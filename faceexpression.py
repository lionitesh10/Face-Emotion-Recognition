# -*- coding: utf-8 -*-
"""FaceExpression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gbl-qX0JphWEda9In3Ojq6Db-Gi9i1ti
"""

!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset

!unzip face-expression-recognition-dataset.zip

import numpy as np
import seaborn as sns
from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator
import matplotlib.pyplot as plt
import os
from keras.layers import Conv2D,BatchNormalization,Activation,Dropout,Flatten,Dense,MaxPooling2D
from keras.optimizers import Adam
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint
import pydot
from keras.utils import plot_model

pic_size=48
base_path="/content/images/images/"
plt.figure(0,figsize=(12,20))
cpt=0

for expression in os.listdir(base_path+"train/"):
  for i in range(1,6):
    cpt+=1
    plt.subplot(7,5,cpt)
    img=load_img(base_path+"train/"+expression+"/"+os.listdir(base_path+"train/"+expression)[i],target_size=(pic_size,pic_size))
    plt.imshow(img,cmap="gray")
plt.tight_layout()
plt.show()

for expression in os.listdir(base_path+"train"):
  print(str(len(os.listdir(base_path+"train/"+expression)))+" "+expression+" images")

datagen_train=ImageDataGenerator()
datagen_validation=ImageDataGenerator()

batch_size=128

train_gen=datagen_train.flow_from_directory(base_path+"train",
                                            target_size=(pic_size,pic_size),
                                            color_mode="grayscale",
                                            batch_size=batch_size,
                                            class_mode='categorical',
                                            shuffle=True
                                            )
validation_gen=datagen_validation.flow_from_directory(base_path+"validation",
                                                      target_size=(pic_size,pic_size),
                                                      color_mode='grayscale',
                                                      batch_size=batch_size,
                                                      class_mode='categorical',
                                                      shuffle=False
                                                      )



nb_classes=7
model=Sequential()

#1st Convolution Layer
model.add(Conv2D(64,(3,3),padding="same",input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#2nd Convolution Layer
model.add(Conv2D(128,(5,5),padding="same"))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#3rd Convolution Layer
model.add(Conv2D(512,(3,3),padding="same"))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#4th Convolution Layer
model.add(Conv2D(512,(3,3),padding="same"))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#Flatten
model.add(Flatten())

#Fully Connected Layers
model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))

model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))

model.add(Dense(nb_classes,activation='softmax'))

opt = Adam(lr=0.0001)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint_cb=ModelCheckpoint("Face_Expression_Model.h5",save_best_only=True)

model.summary()
plot_model(model)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# epochs=50
# 
# history = model.fit_generator(generator=train_gen,
#                                 steps_per_epoch=train_gen.n//train_gen.batch_size,
#                                 epochs=epochs,
#                                 validation_data = validation_gen,
#                                 validation_steps = validation_gen.n//validation_gen.batch_size,
#                                 callbacks=[checkpoint_cb]
#                                 )

import pandas as pd
pd.DataFrame(history.history).plot()

